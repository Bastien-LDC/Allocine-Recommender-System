{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¦Web Scraping Movies Data From AlloCinÃ©.frðŸŽ¬\n",
    "\n",
    "This script builds a DataFrame by web scraping the data from AlloCinÃ© â€” a company which provides information on French cinema. Because of the long delay, we choose to scrape the data in two steps : \n",
    "- First, we scrape the url of each movie with `getMoviesUrl()`\n",
    "- Lastly, we use the url list to scrape the data for each movie with `ScrapeURL()`\n",
    "\n",
    "*ðŸ“Note : We use the popular BeautifulSoup package*\n",
    "\n",
    "## Functions :\n",
    "\n",
    "### `getMoviesUrl(start_page, end_page)` :\n",
    "\n",
    "Saves a CSV file of the url list as `../Movies/Data/movie_url.csv`. The argument must be integers and are used to select the range of pages you want to scrape the data from. The `end_page` is included.\n",
    "\n",
    "### `ScrapeURL(movie_url, dwld_poster)` :\n",
    "\n",
    "Iterate over the list of urls generated by `getMoviesUrl()` and scrape the data for each movie. In the process, we extract :\n",
    "\n",
    "- `id` : AlloCinÃ© movie id\n",
    "- `title` : the movies title (in french)\n",
    "- `release_date`: the release date\n",
    "- `duration`: the movies length\n",
    "- `genres` : the movies genres (as an array)\n",
    "- `directors` : movies directors (as an array)\n",
    "- `actors` : main movie actors (as an array)\n",
    "- `nationality`: nationality of the movies (as an array)\n",
    "- `press_rating`: average press rating (from 0.5 to 5 stars â­â­â­â­â­)\n",
    "- `nb_press_rating`: number of ratings made by the press\n",
    "- `spect_rating`: average AlloCinÃ© users rating (from 0.5 to 5 stars â­â­â­â­â­)\n",
    "- `nb_spect_rating`: number of ratings made by the users/spectators\n",
    "- `summary`: the movies summary\n",
    "- `poster_link`: url of the movies poster\n",
    "\n",
    "*ðŸ“Note : intermediate functions were created to retrieve each individual feature of the dataframe, which makes it easy for debugging.*\n",
    "\n",
    "The function `ScrapeURL()` returns two objects : the data as a dataframe and the url list of errors as a list. In addition the two objects are saved as `../Movies/Data/allocine_movies.csv` and `../Movies/Data/allocine_errors.csv`. At this time, the remaining errors are not handled and integrated to the dataframe, because the issues have not been all identified yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\AppData\\Local\\Temp\\ipykernel_29064\\66211388.py:16: DeprecationWarning: Importing clear_output from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import clear_output\n"
     ]
    }
   ],
   "source": [
    "# Import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from time import time\n",
    "from time import sleep\n",
    "from datetime import timedelta, datetime\n",
    "from urllib.request import urlopen\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "import dateparser\n",
    "import os\n",
    "\n",
    "from warnings import warn\n",
    "from IPython.core.display import clear_output\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: Getting movie infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie ID: `get_movie_ID(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ID(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie ID from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie ID.'''\n",
    "    movie_ID = re.sub(\n",
    "        r\"\\D\", \"\", movie_soup.find(\"nav\", {\"class\": \"third-nav\"}).a[\"href\"]\n",
    "        )\n",
    "    return movie_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie title: `get_movie_title(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_title(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie title from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie title.'''\n",
    "    movie_title = movie_soup.find(\"div\", {\"class\": \"titlebar-title\"}).text.strip()\n",
    "    return movie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie release date: `get_movie_release_date(movie_soup)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert French months to English months: `convert_month(month)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_month(month: str) -> str:\n",
    "    '''\n",
    "    Convert French months into English months for the dateparser to work.\n",
    "    :param month: French month.\n",
    "    :return: English month.'''\n",
    "    if month == \"janvier\":\n",
    "        return \"January\"\n",
    "    elif month == \"fÃ©vrier\":\n",
    "        return \"February\"\n",
    "    elif month == \"mars\":\n",
    "        return \"March\"\n",
    "    elif month == \"avril\":\n",
    "        return \"April\"\n",
    "    elif month == \"mai\":\n",
    "        return \"May\"\n",
    "    elif month == \"juin\":\n",
    "        return \"June\"\n",
    "    elif month == \"juillet\":\n",
    "        return \"July\"\n",
    "    elif month == \"aoÃ»t\":\n",
    "        return \"August\"\n",
    "    elif month == \"septembre\":\n",
    "        return \"September\"\n",
    "    elif month == \"octobre\":\n",
    "        return \"October\"\n",
    "    elif month == \"novembre\":\n",
    "        return \"November\"\n",
    "    elif month == \"dÃ©cembre\":\n",
    "        return \"December\"\n",
    "    else:\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function: `get_movie_release_date(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_release_date(movie_soup: BeautifulSoup) -> datetime:\n",
    "    '''\n",
    "    Scrape the movie release date from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie release date.'''\n",
    "    movie_release_date = movie_soup.find(\"span\", {\"class\": \"date\"})\n",
    "    if movie_release_date:\n",
    "        movie_release_date = movie_release_date.text.strip()\n",
    "        month = movie_release_date.split(' ')[1]\n",
    "        movie_release_date = movie_release_date.replace(month, convert_month(month))\n",
    "        movie_release_date = dateparser.parse(movie_release_date, date_formats=[\"%d %B %Y\"]).date()        \n",
    "    return movie_release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 3, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = get_movie_release_date(movie_html_soup)\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd >= datetime.now().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie duration: `get_movie_duration(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_duration(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie duration from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie duration in minutes.'''\n",
    "    movie_duration = movie_soup.find(\"span\", {\"class\": \"spacer\"}).next_sibling.strip()\n",
    "    if movie_duration != \"\":\n",
    "        duration_timedelta = pd.to_timedelta(movie_duration).components\n",
    "        movie_duration = duration_timedelta.hours * 60 + duration_timedelta.minutes\n",
    "    return movie_duration    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie genres: `get_movie_genres(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genres(movie_soup: BeautifulSoup) -> str:\n",
    "    ''' \n",
    "    Scrape the movie genres from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie genres as a CVS string. None if no genres are found.'''\n",
    "    div_genres = movie_soup.find(\"div\", {\"class\": \"meta-body-item meta-body-info\"})\n",
    "    if div_genres:\n",
    "        movie_genres = [\n",
    "            genre.text\n",
    "            for genre in div_genres.find_all(\"span\", class_=re.compile(r\".*==$\"))\n",
    "            if \"\\n\" not in genre.text\n",
    "        ]\n",
    "        return \", \".join(movie_genres)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie directors: `get_movie_directors(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_directors(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie directors from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie directors as a CSV string. None if no directors are found.'''\n",
    "    div_directors = movie_soup.find_all(\n",
    "            \"div\", {\"class\": \"meta-body-item meta-body-direction\"}\n",
    "        )\n",
    "    # We retrieve the people next to the \"Par\" and \"De\" keywords, and we keep only one instance of each person.\n",
    "    if div_directors:\n",
    "        movie_directors = [\n",
    "            link.text\n",
    "            for directors in div_directors\n",
    "            for link in directors.find_all(\n",
    "                [\"a\", \"span\"], class_=re.compile(r\".*blue-link$\")\n",
    "            )\n",
    "        ]\n",
    "        return \", \".join(set(movie_directors))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie actors: `get_movie_actors(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_actors(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie actors from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie actors as a CSV string. None if no actors are found.'''\n",
    "    div_actors = movie_soup.find(\"div\", {\"class\": \"meta-body-item meta-body-actor\"})\n",
    "    if div_actors:\n",
    "        movie_actors = [actor.text for actor in div_actors.find_all([\"a\", \"span\"])][1:]\n",
    "        return \", \".join(movie_actors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie nationality: `get_movie_nationality(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_nationality(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie nationality from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie nationality as a CSV string.'''\n",
    "    movie_nationality = [\n",
    "            nationality.text.strip()\n",
    "            for nationality in movie_soup.find_all(\"span\", class_=\"nationality\")\n",
    "        ]\n",
    "    return \", \".join(movie_nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie press ratings: `get_movie_press_rating(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_press_rating(movie_soup: BeautifulSoup) -> float:\n",
    "    '''\n",
    "    Scrape the movie average press rating from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie average press rating. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Presse\" in ratings.text:\n",
    "            return float(\n",
    "                re.sub(\n",
    "                    \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                )\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie number of press ratings: `get_movie_press_rating_count(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_press_rating_count(movie_soup: BeautifulSoup) -> int:\n",
    "    '''\n",
    "    Scrape the movie number of press ratings from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie number of press ratings. None if no rating is found.'''\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Presse\" in ratings.text:\n",
    "            # We keep only the number of ratings, and we leave the number of reviews out.\n",
    "            # (eg: re.match(\"\\s\\d+\", \" 10154 notes dont 1327 critiques\").group() returns \" 10154\")\n",
    "            return int(\n",
    "                re.match(\n",
    "                    r\"\\s\\d+\",\n",
    "                    ratings.find(\"span\", {\"class\": \"stareval-review\"}).text,\n",
    "                ).group()\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie spectator ratings: `get_movie_spec_rating(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_spec_rating(movie_soup: BeautifulSoup) -> float:\n",
    "    '''\n",
    "    Scrape the movie average spectators' rating from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie average spec rating. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Spectateurs\" in ratings.text:\n",
    "            return float(\n",
    "                re.sub(\n",
    "                    \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                )\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie number of spec ratings: `get_movie_spec_rating_count(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_spec_rating_count(movie_soup: BeautifulSoup) -> int:\n",
    "    '''\n",
    "    Scrape the movie number of spec ratings from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie number of spec ratings. None if no rating is found.'''\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Spectateurs\" in ratings.text:\n",
    "            # We keep only the number of ratings, and we leave the number of reviews out.\n",
    "            # (eg: re.match(\"\\s\\d+\", \" 10154 notes dont 1327 critiques\").group() returns \" 10154\")\n",
    "            return int(\n",
    "                re.match(\n",
    "                    r\"\\s\\d+\",\n",
    "                    ratings.find(\"span\", {\"class\": \"stareval-review\"}).text\n",
    "                ).group()  \n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie summary: `get_movie_summary(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_summary(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie summary from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie summary. None if no summary is found.'''\n",
    "    movie_summary = movie_soup.find(\n",
    "            \"section\", {\"class\": \"section ovw ovw-synopsis\"}\n",
    "        ).find(\"div\", {\"class\": \"content-txt\"})\n",
    "    if movie_summary:\n",
    "        movie_summary = movie_summary.text.strip()\n",
    "        return unicodedata.normalize(\"NFKC\", movie_summary)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie poster: `get_movie_poster(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_poster(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie poster link from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie poster link.'''\n",
    "    return movie_soup.find(\"img\", {\"class\": \"thumbnail-img\"})[\"src\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download movie poster: `download_movie_poster(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_movie_poster(poster_link: str, movie_name: str) -> None:\n",
    "    '''\n",
    "    Download the movie poster from the poster link.\n",
    "    :param poster_link: The poster link.\n",
    "    :param movie_name: The movie name.\n",
    "    :return: nothing but saves the movie poster as a jpg file.'''\n",
    "    poster = urlopen(poster_link)\n",
    "    poster_path = \"../Movies/Posters/\"\n",
    "    # We create the folder if not exists\n",
    "    os.makedirs(os.path.dirname(poster_path), exist_ok=True) \n",
    "    save_path = f\"{poster_path}{movie_name.replace(' ','_').replace('_:_','_').replace(':_','_').replace(',','')}_poster.jpg\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(poster.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download all movie posters: `download_all_movie_posters(movies_df)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_movie_posters(movies_df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Download all the movie posters from the poster links in the movies dataframe.\n",
    "    :param movies_df: The movies dataframe.\n",
    "    :return: nothing but saves the movie posters as jpg files.'''\n",
    "    for index, row in movies_df.iterrows():\n",
    "        download_movie_poster(row[\"poster_link\"], row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Function: `getMoviesUrl(start_page, end_page)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoviesUrl(start_page: int, end_page: int=None, nb_pages: int=1) -> None:\n",
    "    '''\n",
    "    Scrape the movies urls from the AlloCine website's movie page (http://www.allocine.fr/films/).\n",
    "    It will ignore the movies that has not been released yet.\n",
    "    :param start_page: The first page to scrape.\n",
    "    :param end_page: The last page to scrape (included) (optional).\n",
    "    :param nb_pages: The number of pages to scrape (default 1).\n",
    "    :return: Nothing but saves the list of movies urls in a csv file.'''\n",
    "    if start_page <= 0:\n",
    "        return ValueError('start_page must be positive !')       \n",
    "\n",
    "    # Set the list\n",
    "    movie_url = []\n",
    "\n",
    "    # Preparing the setting and monitoring of the loop\n",
    "    start_time = time()\n",
    "    p_requests = start_page\n",
    "    # We will scrape by default at least 1 page if end_page is not specified, \n",
    "    # or if it is lower than start_page,\n",
    "    # or if the number of pages to scrape is negative.\n",
    "    if nb_pages < 1:\n",
    "        nb_pages = 1\n",
    "    if end_page == None or end_page < start_page:\n",
    "        end_page = start_page + nb_pages - 1\n",
    "    \n",
    "    # Number of movie requests\n",
    "    m_requests = 0\n",
    "        \n",
    "    for p in range(start_page, end_page + 1):\n",
    "\n",
    "        # Get request\n",
    "        url = f'http://www.allocine.fr/films/?page={p}'\n",
    "        response = urlopen(url)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(randint(1,2))\n",
    "            \n",
    "        # Monitoring the requests\n",
    "        elapsed_time = time() - start_time\n",
    "        print(f'>Page Request: {p_requests}; Frequency: {p_requests/elapsed_time} requests/s')\n",
    "        clear_output(wait = True)\n",
    "            \n",
    "        # Warning for non-200 status codes\n",
    "        if response.status != 200:\n",
    "            warn(f'>Page Request: {p_requests}; Status code: {response.status_code}')\n",
    "\n",
    "        # Break the loop if the number of requests is greater than expected\n",
    "        if p_requests > end_page:\n",
    "            warn('Number of requests was greater than expected.')\n",
    "            break\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        html_text = response.read().decode(\"utf-8\")\n",
    "        html_soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "        # Select all the movies url from a single page\n",
    "        movies = html_soup.find_all('h2', 'meta-title')\n",
    "        m_requests += len(movies)\n",
    "        # Count the number of movies not yet released \n",
    "        nr_movies = 0\n",
    "       \n",
    "        # Monitoring the requests\n",
    "        print(f'>Page Request: {p_requests}; Movie Request: {m_requests}')\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(1)\n",
    "        \n",
    "        for movie in movies:\n",
    "            m_url = f'http://www.allocine.fr{movie.a[\"href\"]}'\n",
    "            m_rd = get_movie_release_date(m_url)\n",
    "            # We keep the movie url only if the movie has already been released\n",
    "            if m_rd <= datetime.now().date():\n",
    "                movie_url.append(m_url) \n",
    "            else:\n",
    "                nr_movies += 1\n",
    "        p_requests += 1\n",
    "\n",
    "    # Saving the files\n",
    "    movie_path = '../Movies/Data/'\n",
    "    # We create the folder if not exists\n",
    "    os.makedirs(os.path.dirname(movie_path), exist_ok=True) \n",
    "    print(f'--> Done; {p_requests-1} Page Requests and {m_requests-nr_movies}/{m_requests} Movie Requests in {timedelta(seconds=time()-start_time)}')\n",
    "    r = np.asarray(movie_url)\n",
    "    np.savetxt(f\"{movie_path}movie_url.csv\", r, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: `ScrapeURL(movie_url, dwld_poster)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ScrapeURL(movie_url: list, dwld_poster: bool = False) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "    Scrape the data from the movies urls.\n",
    "    :param movie_url: The list of movies urls.\n",
    "    :param dwld_poster: Boolean to download the movie poster (default False).\n",
    "    :return: The dataframe of the movies and the dataframe of the urls that return an error. Both are saved in a csv file.'''\n",
    "    # init the dataframe\n",
    "    c = [\"id\",\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"duration\",\n",
    "        \"genres\",\n",
    "        \"directors\",\n",
    "        \"actors\",\n",
    "        \"nationality\",\n",
    "        \"press_rating\",\n",
    "        \"nb_press_rating\",\n",
    "        \"spect_rating\",\n",
    "        \"nb_spect_rating\",\n",
    "        \"summary\",\n",
    "        \"poster_link\"\n",
    "    ]\n",
    "    df = pd.DataFrame(columns=c)\n",
    "    \n",
    "    # preparing the setting and monitoring loop\n",
    "    start_time = time()\n",
    "    n_request = 0\n",
    "    \n",
    "    # init list to save errors\n",
    "    errors = []\n",
    "    \n",
    "    # request loop\n",
    "    for url in movie_url:\n",
    "        try :\n",
    "            response = urlopen(url)\n",
    "\n",
    "            # Pause the loop\n",
    "            sleep(randint(1,2))\n",
    "\n",
    "            # Monitoring the requests\n",
    "            n_request += 1\n",
    "            \n",
    "            elapsed_time = time() - start_time\n",
    "            print(f'Request #{n_request}; Frequency: {n_request/elapsed_time} requests/s')\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            # Pause the loop\n",
    "            sleep(randint(1,2))\n",
    "\n",
    "            # Warning for non-200 status codes\n",
    "            if response.status != 200:\n",
    "                warn('Request #{}; Status code: {}'.format(n_request, response.status_code))\n",
    "                errors.append(url)\n",
    "\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            html_text = response.read().decode(\"utf-8\")\n",
    "            movie_html_soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            \n",
    "            # Get the movie data\n",
    "            if movie_html_soup.find('div', 'titlebar-title'):\n",
    "                # Scrape the movie ID \n",
    "                tp_id = get_movie_ID(movie_html_soup)\n",
    "                # Scrape the title\n",
    "                tp_title = get_movie_title(movie_html_soup)\n",
    "                # Scrape the release date\n",
    "                tp_release_dt = get_movie_release_date(movie_html_soup)\n",
    "                # Scrape the duration\n",
    "                tp_duration = get_movie_duration(movie_html_soup)\n",
    "                # Scrape the directors\n",
    "                tp_director = get_movie_directors(movie_html_soup)\n",
    "                # Scrape the actors\n",
    "                tp_actor = get_movie_actors(movie_html_soup)\n",
    "                # Scrape the genres\n",
    "                tp_genre = get_movie_genres(movie_html_soup)\n",
    "                # Scrape the nationality\n",
    "                tp_nation = get_movie_nationality(movie_html_soup)\n",
    "                # Scrape the press ratings\n",
    "                tp_press_rating = get_movie_press_rating(movie_html_soup)\n",
    "                # Scrape the number of press ratings\n",
    "                tp_nb_press_rating = get_movie_press_rating_count(movie_html_soup)\n",
    "                # Scrape the spec ratings\n",
    "                tp_spec_rating = get_movie_spec_rating(movie_html_soup)\n",
    "                # Scrape the number of spec ratings\n",
    "                tp_nb_spec_rating = get_movie_spec_rating_count(movie_html_soup)\n",
    "                # Scrape the summary\n",
    "                tp_summary = get_movie_summary(movie_html_soup)\n",
    "                # Scrape the poster\n",
    "                tp_poster = get_movie_poster(movie_html_soup)\n",
    "                # Download the poster (optional)\n",
    "                if dwld_poster:\n",
    "                    download_movie_poster(tp_poster, tp_title)\n",
    "                \n",
    "                # Append the data\n",
    "                df_tmp = pd.DataFrame({'id': [tp_id],\n",
    "                                       'title': [tp_title],\n",
    "                                       'release_date': [tp_release_dt],\n",
    "                                       'duration': [tp_duration],\n",
    "                                       'genres': [tp_genre],\n",
    "                                       'directors': [tp_director],\n",
    "                                       'actors': [tp_actor],\n",
    "                                       'nationality': [tp_nation],\n",
    "                                       'press_rating': [tp_press_rating],\n",
    "                                       'nb_press_rating': [tp_nb_press_rating],\n",
    "                                       'spect_rating': [tp_spec_rating],\n",
    "                                       'nb_spect_rating': [tp_nb_spec_rating],\n",
    "                                       'summary': [tp_summary],\n",
    "                                       'poster_link': [tp_poster]})\n",
    "                \n",
    "                df = pd.concat([df, df_tmp], ignore_index=True)                \n",
    "        except:\n",
    "            errors.append(url)\n",
    "            warn(f'Request #{n_request} fail; Total errors : {len(errors)}')\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    # monitoring \n",
    "    movie_path = '../Movies/Data/'\n",
    "    # We create the folder if not exists\n",
    "    os.makedirs(os.path.dirname(movie_path), exist_ok=True) \n",
    "    elapsed_time = time() - start_time\n",
    "    print(f'Done; {n_request} requests in {timedelta(seconds=elapsed_time)} with {len(errors)} errors')\n",
    "    clear_output(wait = True)\n",
    "    # Saving files\n",
    "    df.to_csv(f\"{movie_path}allocine_movies.csv\", index=False)\n",
    "    # list to dataframe\n",
    "    errors_df = pd.DataFrame(errors, columns=['url'])\n",
    "    errors_df.to_csv(f\"{movie_path}allocine_errors.csv\")\n",
    "    # return dataframe and errors\n",
    "    return df, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Launching the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting movies urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Done; 20 Page Requests and 300 Movie Requests in 0:00:58.376464\n"
     ]
    }
   ],
   "source": [
    "# Scrape the page from start_page to end_page (included) or with nb_pages\n",
    "start_page = 1\n",
    "end_page = None\n",
    "nb_pages = 20\n",
    "getMoviesUrl(start_page, end_page=end_page, nb_pages=nb_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the list of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the list of urls \n",
    "m_url = pd.read_csv(\"../Movies/Data/movie_url.csv\",names=['url'])\n",
    "m_url = m_url['url'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done; 300 requests in 0:17:16.264138 with 2 errors\n"
     ]
    }
   ],
   "source": [
    "# Scrape the data \n",
    "movies_df, movies_errors = ScrapeURL(m_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
