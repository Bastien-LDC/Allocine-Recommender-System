{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¶**Web Scraping Movies Data From AlloCin√©.fr**üé¨\n",
    "\n",
    "This script builds a DataFrame by web scraping the **movies** data from AlloCin√© ‚Äî a company which provides information on French cinema. Because of the long delay, we choose to scrape the data in two steps : \n",
    "- First, we scrape the url of each movie with `getMoviesUrl(...)`\n",
    "- Lastly, we use the url list to scrape the data for each movie with `ScrapeURL(...)`\n",
    "\n",
    "*üìùNote 1: We use the popular BeautifulSoup package*\n",
    "\n",
    "## **Functions :**\n",
    "\n",
    "### `getMoviesUrl(start_page, end_page, nb_pages)` :\n",
    "\n",
    "Saves a CSV file of the url list as `../Movies/Data/movie_url.csv`. The argument must be integers and are used to select the range of pages (or the number of pages, default 1) you want to scrape the data from. The `end_page` is included. If the `end_page` value is correct (not `None` or >= `start_page`), the `nb_pages` argument is ignored.\n",
    "\n",
    "### `ScrapeURL(movie_url, dwld_poster)` :\n",
    "\n",
    "Iterate over the list of urls generated by `getMoviesUrl(...)` and scrape the data for each movie. In the process, we extract :\n",
    "\n",
    "- `id` : AlloCin√© movie id\n",
    "- `title` : the movie title (in French)\n",
    "- `release_date`: the movie release date\n",
    "- `duration`: the movie length (in minutes)\n",
    "- `genres` : the movie genres (as a CSV string)\n",
    "- `directors` : movie directors (as a CSV string)\n",
    "- `actors` : main movie actors (as a CSV string)\n",
    "- `nationality`: nationality of the movie (as a CSV string)\n",
    "- `press_rating`: average press rating (from 0.5 to 5 stars ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)\n",
    "- `nb_press_rating`: number of ratings made by the press\n",
    "- `spect_rating`: average AlloCin√© users rating (from 0.5 to 5 stars ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)\n",
    "- `nb_spect_rating`: number of ratings made by the users/spectators\n",
    "- `summary`: the movie summary\n",
    "- `poster_link`: url of the movie poster\n",
    "\n",
    "*üìùNote 2: We can choose to download the poster image with the `dwld_poster` argument. If `True`, the poster image is downloaded and saved in the `../Movies/Posters/` folder.*\n",
    "\n",
    "*üìùNote 3: Intermediate functions were created to retrieve each individual feature of the dataframe, which makes it easy for debugging.*\n",
    "\n",
    "The function `ScrapeURL(...)` returns two objects : the data as a dataframe and the url list of errors as a list. In addition the two objects are saved as `../Movies/Data/allocine_movies.csv` and `../Movies/Data/allocine_errors.csv`. At this time, the remaining errors are not handled and integrated to the dataframe, because the issues have not been all identified yet.\n",
    "\n",
    "(‚ö†Ô∏è **Warning** ‚ö†Ô∏è: the process can take a while, depending on the number of pages you choose to scrape. It is recommended to use a dedicated computer for this process, as it can take a long time to complete.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## **Import libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dateparser'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdateparser\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn, filterwarnings\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dateparser'"
     ]
    }
   ],
   "source": [
    "# Import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from time import time\n",
    "from time import sleep\n",
    "from datetime import timedelta, date\n",
    "from urllib.request import urlopen\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "import dateparser\n",
    "import os\n",
    "\n",
    "from warnings import warn, filterwarnings\n",
    "from IPython.core.display import clear_output\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **Functions:** Getting movie infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie ID: `get_movie_ID(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ID(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie ID from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie ID.'''\n",
    "    movie_ID = re.sub(\n",
    "        r\"\\D\", \"\", movie_soup.find(\"nav\", {\"class\": \"third-nav\"}).a[\"href\"]\n",
    "        )\n",
    "    return movie_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie title: `get_movie_title(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_title(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie title from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie title.'''\n",
    "    movie_title = movie_soup.find(\"div\", {\"class\": \"titlebar-title\"}).text.strip()\n",
    "    return movie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie release date: `get_movie_release_date(movie_soup)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert French months to English months: `convert_month(month)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_month(month: str) -> str:\n",
    "    '''\n",
    "    Convert French months into English months for the dateparser to work.\n",
    "    :param month: French month.\n",
    "    :return: English month.'''\n",
    "    if month == \"janvier\":\n",
    "        return \"January\"\n",
    "    elif month == \"f√©vrier\":\n",
    "        return \"February\"\n",
    "    elif month == \"mars\":\n",
    "        return \"March\"\n",
    "    elif month == \"avril\":\n",
    "        return \"April\"\n",
    "    elif month == \"mai\":\n",
    "        return \"May\"\n",
    "    elif month == \"juin\":\n",
    "        return \"June\"\n",
    "    elif month == \"juillet\":\n",
    "        return \"July\"\n",
    "    elif month == \"ao√ªt\":\n",
    "        return \"August\"\n",
    "    elif month == \"septembre\":\n",
    "        return \"September\"\n",
    "    elif month == \"octobre\":\n",
    "        return \"October\"\n",
    "    elif month == \"novembre\":\n",
    "        return \"November\"\n",
    "    elif month == \"d√©cembre\":\n",
    "        return \"December\"\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function: `get_movie_release_date(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_release_date(movie_soup: BeautifulSoup) -> date:\n",
    "    '''\n",
    "    Scrape the movie release date from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie release date.'''\n",
    "    movie_release_date = movie_soup.find(\"span\", {\"class\": \"date\"})\n",
    "    if movie_release_date:\n",
    "        movie_release_date = movie_release_date.text.strip()\n",
    "        month = movie_release_date.split(' ')[1]\n",
    "        movie_release_date = movie_release_date.replace(month, convert_month(month))\n",
    "        movie_release_date = dateparser.parse(movie_release_date, date_formats=[\"%d %B %Y\"]).date()        \n",
    "    return movie_release_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie duration: `get_movie_duration(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_duration(movie_soup: BeautifulSoup) -> int:\n",
    "    '''\n",
    "    Scrape the movie duration from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie duration in minutes.'''\n",
    "    movie_duration = movie_soup.find(\"span\", {\"class\": \"spacer\"}).next_sibling.strip()\n",
    "    if movie_duration != \"\":\n",
    "        duration_timedelta = pd.to_timedelta(movie_duration).components\n",
    "        movie_duration = duration_timedelta.hours * 60 + duration_timedelta.minutes\n",
    "    return int(movie_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie genres: `get_movie_genres(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genres(movie_soup: BeautifulSoup) -> str:\n",
    "    ''' \n",
    "    Scrape the movie genres from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie genres as a CVS string. None if no genres are found.'''\n",
    "    div_genres = movie_soup.find(\"div\", {\"class\": \"meta-body-item meta-body-info\"})\n",
    "    if div_genres:\n",
    "        movie_genres = [\n",
    "            genre.text\n",
    "            for genre in div_genres.find_all(\"span\", class_=re.compile(r\".*==$\"))\n",
    "            if \"\\n\" not in genre.text\n",
    "        ]\n",
    "        return \", \".join(movie_genres)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie directors: `get_movie_directors(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_directors(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie directors from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie directors as a CSV string. None if no directors are found.'''\n",
    "    div_directors = movie_soup.find_all(\n",
    "            \"div\", {\"class\": \"meta-body-item meta-body-direction\"}\n",
    "        )\n",
    "    # We retrieve the people next to the \"Par\" and \"De\" keywords, \n",
    "    # and we keep only one instance of each person.\n",
    "    if div_directors:\n",
    "        movie_directors = [\n",
    "            link.text\n",
    "            for directors in div_directors\n",
    "            for link in directors.find_all(\n",
    "                [\"a\", \"span\"], class_=re.compile(r\".*blue-link$\")\n",
    "            )\n",
    "        ]\n",
    "        return \", \".join(set(movie_directors))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie actors: `get_movie_actors(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_actors(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie actors from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie actors as a CSV string. None if no actors are found.'''\n",
    "    div_actors = movie_soup.find(\"div\", {\"class\": \"meta-body-item meta-body-actor\"})\n",
    "    if div_actors:\n",
    "        # We retrieve the people next to the \"Avec\" keyword\n",
    "        movie_actors = [actor.text for actor in div_actors.find_all([\"a\", \"span\"])][1:]\n",
    "        return \", \".join(movie_actors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie nationality: `get_movie_nationality(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_nationality(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie nationality from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie nationality as a CSV string.'''\n",
    "    movie_nationality = [\n",
    "            nationality.text.strip()\n",
    "            for nationality in movie_soup.find_all(\"span\", class_=\"nationality\")\n",
    "        ]\n",
    "    return \", \".join(movie_nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie press ratings: `get_movie_press_rating(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_press_rating(movie_soup: BeautifulSoup) -> float:\n",
    "    '''\n",
    "    Scrape the movie average press rating from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie average press rating. None if no rating is found.'''\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Presse\" in ratings.text:\n",
    "            # eg: Change from 4,5 to 4.5.\n",
    "            return float(\n",
    "                re.sub(\n",
    "                    \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                )\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie number of press ratings: `get_movie_press_rating_count(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_press_rating_count(movie_soup: BeautifulSoup) -> int:\n",
    "    '''\n",
    "    Scrape the movie number of press ratings from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie number of press ratings. None if no rating is found.'''\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Presse\" in ratings.text:\n",
    "            # We keep only the number of ratings, and we leave the number of reviews out.\n",
    "            # (eg: re.match(\"\\s\\d+\", \" 10154 notes dont 1327 critiques\").group() returns \" 10154\")\n",
    "            return int(\n",
    "                re.match(\n",
    "                    r\"\\s\\d+\",\n",
    "                    ratings.find(\"span\", {\"class\": \"stareval-review\"}).text,\n",
    "                ).group()\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie spectator ratings: `get_movie_spec_rating(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_spec_rating(movie_soup: BeautifulSoup) -> float:\n",
    "    '''\n",
    "    Scrape the movie average spectators' rating from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie average spec rating. None if no rating is found.'''\n",
    "    # get all the available ratings\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Spectateurs\" in ratings.text:\n",
    "            # eg: Change from 4,5 to 4.5.\n",
    "            return float(\n",
    "                re.sub(\n",
    "                    \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                )\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie number of spec ratings: `get_movie_spec_rating_count(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_spec_rating_count(movie_soup: BeautifulSoup) -> int:\n",
    "    '''\n",
    "    Scrape the movie number of spec ratings from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie number of spec ratings. None if no rating is found.'''\n",
    "    movie_ratings = movie_soup.find_all(\"div\", class_=\"rating-item\")\n",
    "    for ratings in movie_ratings:\n",
    "        if \"Spectateurs\" in ratings.text:\n",
    "            # We keep only the number of ratings, and we leave the number of reviews out.\n",
    "            # (eg: re.match(\"\\s\\d+\", \" 10154 notes dont 1327 critiques\").group() returns \" 10154\")\n",
    "            return int(\n",
    "                re.match(\n",
    "                    r\"\\s\\d+\",\n",
    "                    ratings.find(\"span\", {\"class\": \"stareval-review\"}).text\n",
    "                ).group()  \n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie summary: `get_movie_summary(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_summary(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie summary from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie summary. None if no summary is found.'''\n",
    "    movie_summary = movie_soup.find(\n",
    "            \"section\", {\"class\": \"section ovw ovw-synopsis\"}\n",
    "        ).find(\"div\", {\"class\": \"content-txt\"})\n",
    "    if movie_summary:\n",
    "        movie_summary = movie_summary.text.strip()\n",
    "        return unicodedata.normalize(\"NFKC\", movie_summary)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get movie poster: `get_movie_poster(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_poster(movie_soup: BeautifulSoup) -> str:\n",
    "    '''\n",
    "    Scrape the movie poster link from the movie page.\n",
    "    :param movie_soup: BeautifulSoup object of the movie page.\n",
    "    :return: The movie poster link.'''\n",
    "    return movie_soup.find(\"img\", {\"class\": \"thumbnail-img\"})[\"src\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download movie poster: `download_movie_poster(movie_soup)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_movie_poster(poster_link: str, movie_name: str) -> None:\n",
    "    '''\n",
    "    Download the movie poster from the poster link.\n",
    "    :param poster_link: The poster link.\n",
    "    :param movie_name: The movie name.\n",
    "    :return: nothing but saves the movie poster as a jpg file.'''\n",
    "    poster = urlopen(poster_link)\n",
    "    poster_path = \"../Movies/Posters/\"\n",
    "    # We create the folder if not exists\n",
    "    os.makedirs(os.path.dirname(poster_path), exist_ok=True) \n",
    "    save_path = f\"{poster_path}{movie_name.replace(' ','_').replace('_:_','_').replace(':_','_').replace(',','')}_poster.jpg\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(poster.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download all movie posters: `download_all_movie_posters(movies_df)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_movie_posters(movies_df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Download all the movie posters from the poster links in the movies dataframe.\n",
    "    :param movies_df: The movies dataframe.\n",
    "    :return: nothing but saves the movie posters as jpg files.'''\n",
    "    for index, row in movies_df.iterrows():\n",
    "        download_movie_poster(row[\"poster_link\"], row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## **Function:** `getMoviesUrl(start_page, end_page, nb_pages)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getMoviesUrl(start_page: int, end_page: int=None, nb_pages: int=1) -> None:\n",
    "    '''\n",
    "    Scrape the movies urls from the AlloCine website's movie page (http://www.allocine.fr/films/).\n",
    "    The range of pages to scrape goes from start_page to end_page (included) if end_page is not None or <= start_page.\n",
    "    Else, the range of pages to scrape goes from start_page to start_page + nb_pages.\n",
    "    It will ignore the movies that has not been released yet.\n",
    "    :param start_page: The first page to scrape.\n",
    "    :param end_page: The last page to scrape (included) (optional).\n",
    "    :param nb_pages: The number of pages to scrape (default 1).\n",
    "    :return: Nothing but saves the list of movies urls in a csv file.'''\n",
    "    if start_page <= 0:\n",
    "        return ValueError('start_page must be positive !')       \n",
    "\n",
    "    # We ignore dateparse warnings\n",
    "    filterwarnings(\"ignore\",message=\"The localize method is no longer necessary, as this time zone supports the fold attribute\",)\n",
    "    \n",
    "    # Set the list\n",
    "    movie_url = []\n",
    "\n",
    "    # Preparing the setting and monitoring of the loop\n",
    "    start_time = time()\n",
    "    p_requests = start_page\n",
    "    # We will scrape by default at least 1 page if end_page is not specified, \n",
    "    # or if it is lower than start_page,\n",
    "    # or if the number of pages to scrape is negative.\n",
    "    if nb_pages < 1:\n",
    "        nb_pages = 1\n",
    "    if end_page == None or end_page < start_page:\n",
    "        end_page = start_page + nb_pages - 1\n",
    "    \n",
    "    # Number of movie requests\n",
    "    m_requests = 0\n",
    "    \n",
    "    # Loop over the pages\n",
    "    for p in range(start_page, end_page + 1):\n",
    "\n",
    "        # Get request\n",
    "        url = f'http://www.allocine.fr/films/?page={p}'\n",
    "        response = urlopen(url)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(randint(1,2))\n",
    "            \n",
    "        # Monitoring the requests\n",
    "        elapsed_time = time() - start_time\n",
    "        print(f'>Page Request: {p_requests}; Frequency: {p_requests/elapsed_time} requests/s')\n",
    "        clear_output(wait = True)\n",
    "            \n",
    "        # Warning for non-200 status codes\n",
    "        if response.status != 200:\n",
    "            warn(f'>Page Request: {p_requests}; Status code: {response.status_code}')\n",
    "\n",
    "        # Break the loop if the number of requests is greater than expected\n",
    "        if p_requests > end_page:\n",
    "            warn('Number of requests was greater than expected.')\n",
    "            break\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        html_text = response.read().decode(\"utf-8\")\n",
    "        html_soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "        # Select all the movies url from a single page\n",
    "        movies = html_soup.find_all('h2', 'meta-title')\n",
    "        m_requests += len(movies)\n",
    "        # Count the number of movies not yet released \n",
    "        nr_movies = 0\n",
    "       \n",
    "        # Monitoring the requests\n",
    "        print(f'>Page Request: {p_requests}; Movie Request: {m_requests}')\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(1)\n",
    "        \n",
    "        for movie in movies:\n",
    "            m_url = f'http://www.allocine.fr{movie.a[\"href\"]}'\n",
    "            m_soup = BeautifulSoup(urlopen(m_url), 'html.parser')\n",
    "            m_rd = get_movie_release_date(m_soup)\n",
    "            # We keep the movie url only if the movie has already been released.\n",
    "            if m_rd != None and m_rd <= datetime.now().date():\n",
    "                movie_url.append(m_url) \n",
    "            else:\n",
    "                nr_movies += 1\n",
    "        p_requests += 1\n",
    "\n",
    "    # Saving the files\n",
    "    movie_path = '../Movies/Data/'\n",
    "    # We create the folder if not exists\n",
    "    os.makedirs(os.path.dirname(movie_path), exist_ok=True) \n",
    "    print(f'--> Done; {p_requests-start_page} Page Requests and {m_requests-nr_movies}/{m_requests} Movie Requests in {timedelta(seconds=time()-start_time)}')\n",
    "    r = np.asarray(movie_url)\n",
    "    np.savetxt(f\"{movie_path}movie_url.csv\", r, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **Function:** `ScrapeURL(movie_url, dwld_poster)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ScrapeURL(movie_url: list, dwld_poster: bool = False) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "    Scrape the data from the movies page urls.\n",
    "    :param movie_url: The list of movies page urls.\n",
    "    :param dwld_poster: Boolean to download the movie poster (default False).\n",
    "    :return: The dataframe of the movies and the dataframe of the urls that return an error. \n",
    "    Both are saved into csv files.'''\n",
    "    # init the dataframe\n",
    "    c = [\"id\",\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"duration\",\n",
    "        \"genres\",\n",
    "        \"directors\",\n",
    "        \"actors\",\n",
    "        \"nationality\",\n",
    "        \"press_rating\",\n",
    "        \"nb_press_rating\",\n",
    "        \"spect_rating\",\n",
    "        \"nb_spect_rating\",\n",
    "        \"summary\",\n",
    "        \"poster_link\"\n",
    "    ]\n",
    "    df = pd.DataFrame(columns=c)\n",
    "    \n",
    "    # preparing the setting and monitoring loop\n",
    "    start_time = time()\n",
    "    n_request = 0\n",
    "    \n",
    "    # init list to save errors\n",
    "    errors = []\n",
    "    \n",
    "    # request loop\n",
    "    for url in movie_url:\n",
    "        try :\n",
    "            response = urlopen(url)\n",
    "\n",
    "            # Pause the loop\n",
    "            sleep(randint(1,2))\n",
    "\n",
    "            # Monitoring the requests\n",
    "            n_request += 1\n",
    "            \n",
    "            elapsed_time = time() - start_time\n",
    "            print(f'Request #{n_request}; Frequency: {n_request/elapsed_time} requests/s')\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            # Pause the loop\n",
    "            sleep(randint(1,2))\n",
    "\n",
    "            # Warning for non-200 status codes\n",
    "            if response.status != 200:\n",
    "                warn('Request #{}; Status code: {}'.format(n_request, response.status_code))\n",
    "                errors.append(url)\n",
    "\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            html_text = response.read().decode(\"utf-8\")\n",
    "            movie_html_soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            \n",
    "            # Get the movie data\n",
    "            if movie_html_soup.find('div', 'titlebar-title'):\n",
    "                # Scrape the movie ID \n",
    "                tp_id = get_movie_ID(movie_html_soup)\n",
    "                # Scrape the title\n",
    "                tp_title = get_movie_title(movie_html_soup)\n",
    "                # Scrape the release date\n",
    "                tp_release_dt = get_movie_release_date(movie_html_soup)\n",
    "                # Scrape the duration\n",
    "                tp_duration = get_movie_duration(movie_html_soup)\n",
    "                # Scrape the directors\n",
    "                tp_director = get_movie_directors(movie_html_soup)\n",
    "                # Scrape the actors\n",
    "                tp_actor = get_movie_actors(movie_html_soup)\n",
    "                # Scrape the genres\n",
    "                tp_genre = get_movie_genres(movie_html_soup)\n",
    "                # Scrape the nationality\n",
    "                tp_nation = get_movie_nationality(movie_html_soup)\n",
    "                # Scrape the press ratings\n",
    "                tp_press_rating = get_movie_press_rating(movie_html_soup)\n",
    "                # Scrape the number of press ratings\n",
    "                tp_nb_press_rating = get_movie_press_rating_count(movie_html_soup)\n",
    "                # Scrape the spec ratings\n",
    "                tp_spec_rating = get_movie_spec_rating(movie_html_soup)\n",
    "                # Scrape the number of spec ratings\n",
    "                tp_nb_spec_rating = get_movie_spec_rating_count(movie_html_soup)\n",
    "                # Scrape the summary\n",
    "                tp_summary = get_movie_summary(movie_html_soup)\n",
    "                # Scrape the poster\n",
    "                tp_poster = get_movie_poster(movie_html_soup)\n",
    "                # Download the poster (optional)\n",
    "                if dwld_poster:\n",
    "                    download_movie_poster(tp_poster, tp_title)\n",
    "                \n",
    "                # Append the data\n",
    "                df_tmp = pd.DataFrame({'id': [tp_id],\n",
    "                                       'title': [tp_title],\n",
    "                                       'release_date': [tp_release_dt],\n",
    "                                       'duration': [tp_duration],\n",
    "                                       'genres': [tp_genre],\n",
    "                                       'directors': [tp_director],\n",
    "                                       'actors': [tp_actor],\n",
    "                                       'nationality': [tp_nation],\n",
    "                                       'press_rating': [tp_press_rating],\n",
    "                                       'nb_press_rating': [tp_nb_press_rating],\n",
    "                                       'spect_rating': [tp_spec_rating],\n",
    "                                       'nb_spect_rating': [tp_nb_spec_rating],\n",
    "                                       'summary': [tp_summary],\n",
    "                                       'poster_link': [tp_poster]})\n",
    "                \n",
    "                df = pd.concat([df, df_tmp], ignore_index=True)                \n",
    "        except:\n",
    "            errors.append(url)\n",
    "            warn(f'Request #{n_request} fail; Total errors : {len(errors)}')\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    # monitoring \n",
    "    movie_path = '../Movies/Data/'\n",
    "    # We create the folder if not exists\n",
    "    os.makedirs(os.path.dirname(movie_path), exist_ok=True) \n",
    "    elapsed_time = time() - start_time\n",
    "    print(f'Done; {n_request} requests in {timedelta(seconds=elapsed_time)} with {len(errors)} errors')\n",
    "    clear_output(wait = True)\n",
    "    # Saving files\n",
    "    df.to_csv(f\"{movie_path}allocine_movies.csv\", index=False)\n",
    "    # list to dataframe\n",
    "    errors_df = pd.DataFrame(errors, columns=['url'])\n",
    "    errors_df.to_csv(f\"{movie_path}allocine_errors.csv\")\n",
    "    # return dataframe and errors\n",
    "    return df, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## **Launching the script**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting movies urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the page from start_page to end_page (included) or with nb_pages\n",
    "start_page = 1\n",
    "end_page = None\n",
    "nb_pages = 1\n",
    "getMoviesUrl(start_page, end_page=end_page, nb_pages=nb_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the list of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the list of urls \n",
    "m_url = pd.read_csv(\"../Movies/Data/movie_url.csv\",names=['url'])\n",
    "m_url = m_url['url'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Scrape the data \n",
    "movies_df, movies_errors = ScrapeURL(m_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
