{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¶**AlloCin√© Recommender System**üîéüìç\n",
    "\n",
    "Once we cleaned the data, we can start to build our recommender system. The data that will be used is located in the `../Cleaned Data/` folder.\n",
    "\n",
    "**Types of Recommender System:**\n",
    "\n",
    "There are two types of recommender system: **`content-based`** and **`collaborative-filtering`**.\n",
    "\n",
    "- **`Content-based`:** this recommender system is based only on the characteristics of the products. Here, we will recommend an item to a user by comparing the features between items and recommend the items with the highest similarity. We will test two different methods:\n",
    "    - Picking a random movie and recommending the ten most similar movies to it.\n",
    "    - Forming a user profile vector based on the user's movie ratings and recommending the ten movies that fit best to the user's profile.\n",
    "    \n",
    "     \n",
    "\n",
    "- **`Collaborative-filtering`:** this recommender system is based on the interactions between users and the items. \n",
    "    - `Memory-based`: Calculation of similarities between users or between products to recommend the right product.\n",
    "        - `User-based CF`: Suggest products that have been well rated by similar users.\n",
    "        - `Item-based CF`: Offer products that are well rated and similar to products already used.\n",
    "    - `Model-based`: Finding a pattern explaining browsing and preferences behaviors.\n",
    "\n",
    "By the format of our data, we will only be able to perform an `item-based CF` for the `memory-based` method as we don't have any information about the users, only their ratings and the features of the items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Import libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import glob\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances, euclidean_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from ast import literal_eval\n",
    "from warnings import filterwarnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop # Used to get the French stop-words\n",
    "from IPython.display import clear_output\n",
    "import traceback\n",
    "\n",
    "# We ignore dateparse warnings\n",
    "filterwarnings(\"ignore\",message=\"The localize method is no longer necessary, as this time zone supports the fold attribute\")\n",
    "# We ignore reindexing warnings\n",
    "filterwarnings(\"ignore\",message=\"Boolean Series key will be reindexed\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load the csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv():\n",
    "    '''\n",
    "    Load the csv files and return a dict of dataframes.\n",
    "    '''\n",
    "    root_path = f\"../Cleaned Data/\"\n",
    "    movies = pd.read_csv(f\"{root_path}movies.csv\", converters={\"genres\": literal_eval}) # Load list look-alike string as type list\n",
    "    series = pd.read_csv(f\"{root_path}series.csv\", converters={\"genres\": literal_eval})\n",
    "    for c in [\"actors\", \"directors\", \"nationality\"]:\n",
    "        movies[c] = movies[c].apply(lambda x: literal_eval(x) if type(x) == str else [])\n",
    "        series[c] = series[c].apply(lambda x: literal_eval(x) if type(x) == str else [])\n",
    "    press_movies = pd.read_csv(f\"{root_path}press_movies.csv\")\n",
    "    press_series = pd.read_csv(f\"{root_path}press_series.csv\")\n",
    "    user_movies = pd.read_csv(f\"{root_path}user_movies.csv\")\n",
    "    user_series = pd.read_csv(f\"{root_path}user_series.csv\")\n",
    "    #user_series = pd.read_csv(f\"../Series/Ratings/Webscraping_Series_Ratings_user_ratings_series_#1-1.csv\")\n",
    "    return {\"movies\":movies, \"series\":series, \"press_movies\":press_movies, \"press_series\":press_series, \"user_movies\":user_movies, \"user_series\":user_series}\n",
    "data = load_csv()\n",
    "movies, series, press_movies, press_series, user_movies, user_series = data[\"movies\"], data[\"series\"], data[\"press_movies\"], data[\"press_series\"], data[\"user_movies\"], data[\"user_series\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Content-based (CB)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stop-words: `get_stop_words()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    '''\n",
    "    Get the French and English stop-words for tagging.\n",
    "    :return: list of French and Enlish stop-words.\n",
    "    '''\n",
    "    # turn French stop-words into a list\n",
    "    stop_words = list(fr_stop)\n",
    "    # Load extra stop-words in French and in English\n",
    "    with open(\"stop_words_french.txt\",'r', encoding='UTF-8') as file:\n",
    "        additional_stopwords = file.readlines()\n",
    "        additional_stopwords = [line.rstrip() for line in additional_stopwords]\n",
    "    with open(\"stop_words_eng.txt\",'r', encoding='UTF-8') as file:\n",
    "        additional_stopwords_eng = file.readlines()\n",
    "        additional_stopwords_eng = [line.rstrip() for line in additional_stopwords_eng]\n",
    "    \n",
    "    # Add the additional French stop-words to the list of stop-words if they are not already in it\n",
    "    for word, word_eng in zip(additional_stopwords,additional_stopwords_eng):\n",
    "        if word not in stop_words:\n",
    "            stop_words.append(word)\n",
    "        if word_eng not in stop_words:\n",
    "            stop_words.append(word_eng)\n",
    "    stop_words.extend([\"\",\" \",\"#\",\"-\",\":\",\"(\",\")\"])\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tags: `get_tags(df, stop_words, cols_to_get)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(df: pd.DataFrame=None, stop_words: list=get_stop_words(), cols_to_get: str=\"title\"):\n",
    "    '''\n",
    "    Get the tags of the movies from the title and/or summary.\n",
    "    :param df: Dataframe to transform.\n",
    "    :param stop_words: List of stop-words to remove from the tags.\n",
    "    :param col_to_get: Columns to get the tags from.\n",
    "    '''\n",
    "    try:\n",
    "        # We remove unecessary punctuation and characters from the title \n",
    "        # And store the title's keywords in a list\n",
    "        rmv_char = r\"(!|#|:|\\$|\\%|\\^|\\&|\\*|\\(|\\)|-|\\+|/|\\?|\\.+|\\d)\"\n",
    "        df[\"tags\"] = df[cols_to_get].apply(lambda x: re.split(\" |,|\\. |\\.\\.\\.|\\\"|'|-\", re.sub(rmv_char, \" \", x)))\n",
    "        df[\"tags\"] = df[\"tags\"].apply(lambda x: [i for i in x if i.lower() not in stop_words])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummies df: `get_dummies_df(df, kepp_cols, cols_to_dummies)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies_df(df_key: str=\"movies\", keep_cols: list=None, cols_to_dummies: list=[\"genres\"]):\n",
    "    '''\n",
    "    Get a dataframe with the dummies of the column cols_to_dummies.\n",
    "    :param df_key: Key of the dataframe from dict 'data' to transform.\n",
    "    :param keep_cols: List of columns to keep.\n",
    "    :param cols_to_dummies: List of columns to transform to dummies.\n",
    "    :return: Original dataframe with the concatenated dummies datframe of the columns cols_to_dummies.\n",
    "    '''\n",
    "    try:\n",
    "        df_dummies = data[df_key][keep_cols]\n",
    "        # We drop the movies with no user rating\n",
    "        df_dummies = df_dummies.dropna(subset=[\"user_rating\"], axis=0)\n",
    "        df_dummies = df_dummies.reset_index(drop=True)\n",
    "        # We keep only the release year as a recommendation feature\n",
    "        df_dummies[\"release_date\"] = df_dummies[\"release_date\"].apply(lambda x: int(x.split(\"-\")[0]))\n",
    "        \n",
    "        # We add the tag column to the dataframe\n",
    "        if \"tags\" in cols_to_dummies:\n",
    "            df_dummies = get_tags(df=df_dummies) \n",
    "\n",
    "        non_dummy_cols = df_dummies.shape[1]\n",
    "\n",
    "        # We create binary variables for each cols_to_dummies feature by One-Hot encoding their values\n",
    "        for col in cols_to_dummies:  \n",
    "            encode_col = pd.get_dummies(df_dummies[col].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "            df_dummies = pd.concat([df_dummies, encode_col], axis=1)\n",
    "        \n",
    "        # We sort the movies by title and release date\n",
    "        df_dummies.sort_values(by=[\"title\", \"release_date\"], ascending=[True,False]).reset_index(drop=True, inplace=True)                   \n",
    "        \n",
    "        # We replace NaN values in the dummy columns with 0\n",
    "        df_dummies.iloc[:,non_dummy_cols:] = df_dummies.iloc[:,non_dummy_cols:].fillna(0)\n",
    "        # We add +1 to the people who are both actors and directors for the same movie\n",
    "        duplicated_cols = df_dummies.columns[df_dummies.columns.duplicated()]\n",
    "        for col in duplicated_cols:\n",
    "            df_dummies[col] = df_dummies[col].sum(axis=1)\n",
    "        # We remove duplicated dummies columns (from people who are both actors and directors)\n",
    "        df_dummies = df_dummies.loc[:,~df_dummies.columns.duplicated()].copy()\n",
    "               \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc()   \n",
    "        return None\n",
    "    return df_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create utility matrix: `create_utility_matrix(v_type)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_utility_matrix(v_type: str=\"movies\", dummies_df: pd.DataFrame=None, matrix_type: str=\"user-item\"):\n",
    "    '''\n",
    "    Create the utility matrix for the movies or series.\n",
    "    :return: Utility matrix.\n",
    "    '''\n",
    "    try:\n",
    "        users_df = data[f\"user_{v_type}\"].copy()\n",
    "        # In the user_movies df, remove users who appears less than 5 times (=> have made less than 5 reviews)\n",
    "        users_df = users_df.groupby('user_id').filter(lambda x: len(x) >= 5)        \n",
    "\n",
    "        if matrix_type == \"user-features\":\n",
    "            utility_matrix = pd.merge(users_df, dummies_df, left_on=\"movie_id\", right_on=\"id\", how=\"left\")\n",
    "\n",
    "        # Pivot table to get the user-movie utility matrix\n",
    "        if matrix_type == \"user-item\":\n",
    "            utility_matrix = users_df.pivot(index='user_id', columns='movie_id', values='user_rating').fillna(0)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    return utility_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize: `normalize(matrix, dummies_df, binary, multiply_by_ratings, scaler, vectorize)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(matrix: pd.DataFrame, dummies_df: pd.DataFrame=None, numerical_cols: list=[], cols_to_scale: list=[], binary: bool=False, multiply_by_ratings: bool=False, scaler: str=\"None\", vectorize: bool=False):\n",
    "    '''\n",
    "    Normalize the matrix.\n",
    "    :param matrix: Matrix to normalize.\n",
    "    :param dummies_df: Dummies dataframe with ratings.\n",
    "    :param numerical_cols: List of extra numerical columns we added to the dummies df.\n",
    "    :param cols_to_scale: List of the numerical columns to scale.\n",
    "    :param binary: If True, we normalize the matrix by dividing the term occurrence (1/0) by the number of features in the movie.\n",
    "    :param multiply_by_ratings: If True, we multiply the matrix by the ratings of the movies.\n",
    "    :param scaler: Method to use for normalization.\n",
    "    :param vectorize: If True, we vectorize the matrix.\n",
    "    :return: Normalized matrix or normalized user vector.\n",
    "    '''\n",
    "    try:\n",
    "        scaled_matrix = matrix.copy()\n",
    "        if binary: # Normalize the matrix by dividing the term occurrence (1/0) by the number of features in the movie.\n",
    "            scaled_matrix.iloc[:,len(numerical_cols):] = scaled_matrix.iloc[:,len(numerical_cols):] / scaled_matrix.iloc[:,len(numerical_cols):].sum(axis=1).values[:,None]\n",
    "        if multiply_by_ratings: # Weigh the features by the ratings of the movies.\n",
    "            scaled_matrix.iloc[:,len(numerical_cols):] = scaled_matrix.iloc[:,len(numerical_cols):] * dummies_df[\"user_rating\"].values[:,None]\n",
    "        if vectorize: # We vectorize the matrix.\n",
    "            user_vector = scaled_matrix.sum().values.reshape(1,-1)\n",
    "            if scaler == \"l1\":\n",
    "                user_vector = normalize(user_vector, axis=1, norm='l1')\n",
    "            elif scaler == \"l2\":\n",
    "                user_vector = normalize(user_vector, axis=1, norm='l2')           \n",
    "            return user_vector\n",
    "        \n",
    "        if scaler == \"standard\": # Apply standard normalization on the matrix and the cols_to_scale columns.         \n",
    "            scaled_matrix.iloc[:,len(numerical_cols):] = (scaled_matrix.iloc[:,len(numerical_cols):] - scaled_matrix.iloc[:,len(numerical_cols):].mean(axis=0)) / scaled_matrix.iloc[:,len(numerical_cols):].std(axis=0)\n",
    "            if cols_to_scale:\n",
    "                scaled_matrix[cols_to_scale] = (scaled_matrix[cols_to_scale] - scaled_matrix[cols_to_scale].mean(axis=0)) / scaled_matrix[cols_to_scale].std(axis=0)\n",
    "        if scaler == \"l1\": # Apply standard normalization on the matrix and the cols_to_scale columns.\n",
    "            scaled_matrix.iloc[:,len(numerical_cols):] = normalize(scaled_matrix.iloc[:,len(numerical_cols):], axis=1, norm='l1',)\n",
    "            if cols_to_scale:\n",
    "                scaled_matrix[cols_to_scale] = normalize(scaled_matrix[cols_to_scale], axis=1, norm='l1')\n",
    "        if scaler == \"l2\": # Apply standard normalization on the matrix and the cols_to_scale columns.\n",
    "            scaled_matrix.iloc[:,len(numerical_cols):] = normalize(scaled_matrix.iloc[:,len(numerical_cols):], axis=1, norm='l2')\n",
    "            if cols_to_scale:\n",
    "                scaled_matrix[cols_to_scale] = normalize(scaled_matrix[cols_to_scale], axis=1, norm='l2')\n",
    "        elif scaler == \"min-max\": # Apply min-max normalization on the matrix and the cols_to_scale columns.\n",
    "            scaled_matrix.iloc[:,len(numerical_cols):] = (scaled_matrix.iloc[:,len(numerical_cols):] - scaled_matrix.iloc[:,len(numerical_cols):].min(axis=0)) / (scaled_matrix.iloc[:,len(numerical_cols):].max(axis=0) - scaled_matrix.iloc[:,len(numerical_cols):].min(axis=0))\n",
    "            if cols_to_scale:\n",
    "                scaled_matrix[cols_to_scale] = (scaled_matrix[cols_to_scale] - scaled_matrix[cols_to_scale].min(axis=0)) / (scaled_matrix[cols_to_scale].max(axis=0) - scaled_matrix[cols_to_scale].min(axis=0))\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    return scaled_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Similarity: `compute_similarity(feature_df, user_vector, similarity_metric)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(feature_df: pd.DataFrame=None, user_vector: np.array=None, similarity_metric: str=\"cosine\"):\n",
    "    '''\n",
    "    Compute the similarity between the movies/series vectors.\n",
    "    :param feature_df: Dataframe with the movies/series features to compute the similarity.\n",
    "    :param user_vector: User vector to compute the similarity with the movies/series vectors.\n",
    "    :param similarity_metric: Similarity metric to use (cosine|euclidean).\n",
    "    :return: Similarity matrix between the movies/series vectors.\n",
    "    '''\n",
    "    try:\n",
    "        # We compute the similarity between the user vector and the  movies/series vectors if user_vector is not None.\n",
    "        if user_vector is not None:\n",
    "            if similarity_metric == \"cosine\":\n",
    "                return cosine_similarity(user_vector, feature_df)\n",
    "            if similarity_metric == \"euclidean\":\n",
    "                return euclidean_distances(user_vector, feature_df)      \n",
    "            else:\n",
    "                print(f\"Error: {similarity_metric} is not a valid similarity metric.\")        \n",
    "        # We compute the similarity matrix between the movies/series vectors\n",
    "        else:\n",
    "            if similarity_metric == \"cosine\":\n",
    "                return cosine_similarity(feature_df)\n",
    "            if similarity_metric == \"euclidean\":\n",
    "                return euclidean_distances(feature_df)        \n",
    "            else:\n",
    "                print(f\"Error: {similarity_metric} is not a valid similarity metric.\")    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CB recommendations: `CB_recommendations(title, sim_matrix, nb_recos, dummies_df)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_recommender(title: str=\"The Batman\", sim_matrix: np.array=None, nb_recos: int=10, dummies_df: pd.DataFrame=None):\n",
    "    '''\n",
    "    Get the recommendations for a movie.\n",
    "    :param title: Title of the movie to get the recommendations for.\n",
    "    :param sim_matrix: Similarity matrix (cosine, euclidian, K-NN).\n",
    "    :param nb_recos: Number of recommendations to get.\n",
    "    :param dummies_df: Dataframe with the dummies of the movies.\n",
    "    :return: Tuples of the recommended movies' titles, with similarity value and IDs.      \n",
    "    '''\n",
    "    CB_recos = [] # Initialization of the list of recommendations\n",
    "    title_keywords = title.split(\" \") # We split the title into keywords\n",
    "    title_list = [] # Initialization of the list of titles\n",
    "    movies_ids_list = [] # Initialization of the list of movie IDs\n",
    "    # We collect all the movies titles (with their respective id) which contain all the keywords of the title variable\n",
    "    for full_title, id in zip(dummies_df.title.values.tolist(), dummies_df.id.values.tolist()):\n",
    "        if all(word.lower() in full_title.lower() for word in title_keywords):\n",
    "            title_list.append((full_title,id))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    # If we get a direct match, we return the title.    \n",
    "    if len(title_list) == 1:\n",
    "        current_title = title_list[0]\n",
    "    # Else, we get all the movies with similar names and ask the user to choose one.\n",
    "    elif len(title_list) > 1:\n",
    "        print(\"Several movies found with similar title. Please choose one of the following:\")\n",
    "        for i, item in enumerate(title_list,1):\n",
    "            print(i, f': {item}', sep='',end='\\n')\n",
    "        choice = -1\n",
    "        while choice < 1 or choice > len(title_list):\n",
    "            choice = int(input(\"Enter the number of the movie: \"))\n",
    "        current_title = title_list[choice-1]\n",
    "    else:\n",
    "        return f'Error: The movie {title} requested was not found.'\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    # If the movie is in the database\n",
    "    idx = dummies_df.index[dummies_df.id == current_title[1]][0] # We retrieve the index of the movie by its id\n",
    "    score_series = pd.Series(sim_matrix[idx]).drop(idx).sort_values(ascending=False) # We sort the similarity matrix of the movies and we drop the movie itself\n",
    "    top_nbrecos = list(score_series.iloc[0:nb_recos].index) # We select the top nb_recos movies \n",
    "    # We store the titles of the top nb_recos movies in the list CB_recos and return it\n",
    "    for i in top_nbrecos:             \n",
    "        CB_recos.append((dummies_df.title[i], sim_matrix[idx][i]))\n",
    "        movies_ids_list.append(dummies_df.id[i])\n",
    "    \n",
    "    return (current_title[0],CB_recos), (current_title[1],movies_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CB user recommendations: `CB_user_recommendations(user_movies, dummies_df, nb_recos)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_user_recommendations(user_movies_df: pd.DataFrame, dummies_df: pd.DataFrame=None, feature_matrix: pd.DataFrame=None, norm_feature_matrix: pd.DataFrame=None, drop_movies: bool=True, top_movies: int=5, nb_recos: int=10):\n",
    "    '''\n",
    "    Get the recommendations for a user.\n",
    "    :param user_movies_df: Dataframe of the user movie ratings with user and movie IDs.\n",
    "    :param dummies_df: Dataframe with the dummies and average ratings of the movies.\n",
    "    :param feature_matrix: Feature matrix of all the movies.\n",
    "    :param norm_feature_matrix: Normalized feature matrix of all the movies.\n",
    "    :param drop_movies: Boolean to drop the movies already watched by the user from the recommendations.\n",
    "    :param top_movies: Top top_movies favourite movies from the user's profile.\n",
    "    :param nb_recos: Number of recommendations to get.\n",
    "    :return: Tuples of the recommended movies' titles, with similarity value and IDs.   \n",
    "    '''    \n",
    "    CB_recos = [] # Initialization of the list of recommendations\n",
    "    movies_ids_list = [] # Initialization of the list of movie IDs\n",
    "\n",
    "    # In the user_movies df, remove users who appears less than 5 times (-> have made less than 5 reviews)\n",
    "    user_movies = user_movies_df.groupby('user_id').filter(lambda x: len(x) >= 5)    \n",
    "    # Get all unique user ids sorted by the descending number of reviews\n",
    "    user_ids = user_movies.user_id.value_counts().index\n",
    "\n",
    "    # Ask the user to choose a user\n",
    "    index = -1\n",
    "    while index < 0 or index >= len(user_ids):\n",
    "        index = int(input(f\"Enter the number of the user you want to get recommendations for (between 1 and {len(user_ids)}): \")) - 1 \n",
    "    # Get all movies ID from user ID and their ratings\n",
    "    user_movie_list = user_movies[user_movies.user_id == user_ids[index]][[\"user_name\",\"movie_id\", \"user_rating\"]]\n",
    "    user_name = user_movie_list.user_name.values[0]\n",
    "    # Get all movies rated by the user\n",
    "    user_profile = dummies_df.loc[dummies_df[\"id\"].isin(user_movie_list.movie_id.to_list())]    \n",
    "    user_profile = user_profile.assign(user_rating=user_movie_list.user_rating.to_list())\n",
    "    # We retrieve the feature matrix of the user profile\n",
    "    features_user_matrix = feature_matrix.loc[user_profile.index]\n",
    "    # We create and normalize the user profile\n",
    "    norm_user_profile = normalize_matrix(features_user_matrix, dummies_df=user_profile, binary=False, multiply_by_ratings=True, scaler=\"l2\", vectorize=True)\n",
    "\n",
    "    #***************************************************************\n",
    "    # We plot the most important features of the user profile\n",
    "    #***************************************************************\n",
    "    nup = pd.DataFrame(norm_user_profile[0], index=features_user_matrix.columns, columns=[\"norm_value\"])\n",
    "    nup.sort_values(by=\"norm_value\", ascending=False, inplace=True)\n",
    "    nup = nup[nup.norm_value != 0].iloc[:30]\n",
    "    plt.figure(figsize=(19, 8))\n",
    "    plt.title(f\"Normalized User Profile for user \\\"{user_movie_list.user_name.values[0]}\\\"\", fontsize=20, fontweight=\"bold\")\n",
    "    ax = sns.barplot(x=nup.index, y=nup.norm_value)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "    plt.show()\n",
    "\n",
    "    #*********************************************\n",
    "    # Display the favourite movies of the user\n",
    "    #*********************************************\n",
    "    user_profile.sort_values(by=\"user_rating\", ascending=False, inplace=True)\n",
    "    user_movies_titles = [(user_profile.title.values[j], user_profile.user_rating.values[j]) for j in range(top_movies)]\n",
    "    display_recos((user_name, user_movies_titles), \n",
    "                  (None, user_profile.id.values[:top_movies]), \n",
    "                  v_type=\"movies\", reco_type=\"user_profile\")\n",
    "\n",
    "    # We compute the similarity between the user profile and the feature matrix\n",
    "    sim_matrix = compute_similarity(norm_feature_matrix, norm_user_profile, similarity_metric=\"cosine\")\n",
    "    # We sort the similarity matrix of the movies and we drop (or not) the movies already watched by the user.\n",
    "    score_series = pd.Series(sim_matrix[0]).drop(user_profile.index).sort_values(ascending=False) if drop_movies else pd.Series(sim_matrix[0]).sort_values(ascending=False)\n",
    "    top_nbrecos = list(score_series.iloc[0:nb_recos].index) # We select the top nb_recos movies \n",
    "    # We store the titles of the top nb_recos movies in the list CB_recos and return it\n",
    "    for i in top_nbrecos:             \n",
    "        CB_recos.append((dummies_df.title[i], sim_matrix[0][i]))\n",
    "        movies_ids_list.append(dummies_df.id[i])\n",
    "    \n",
    "    return (user_name,CB_recos), (None, movies_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display recommendations: `display_recos(m_titles, m_ids)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recos(v_titles: tuple, v_ids: tuple, v_type: str=\"movies\", reco_type: str=\"item-item\"):\n",
    "    '''\n",
    "    Display the recommendations for a movie/series.\n",
    "    :param v_titles: Tuple of the requested movie/series title and recommended movies/series titles.\n",
    "    :param v_ids: Tuple of the requested movie/series id and recommended movies/series ids.    \n",
    "    :param v_type: 'movies' or 'series'.\n",
    "    :param reco_type: 'item-item', 'user-item' or 'user-profile'.\n",
    "    '''\n",
    "    try:\n",
    "        if reco_type == \"item-item\":\n",
    "            #**************************************\n",
    "            # We display the requested movie\n",
    "            #**************************************\n",
    "            f1 = plt.figure(figsize=(8,8))\n",
    "            f1.suptitle(\"The movie you requested is:\\n\", fontsize=20, fontweight='bold')\n",
    "            title = v_titles[0]\n",
    "            split_title = title.split(\" \")\n",
    "            len_title = len(title)\n",
    "            title = title if len_title <= 36 else \" \".join(split_title[:len(split_title)//2]) + \"\\n\" + \" \".join(split_title[len(split_title)//2:])\n",
    "            plt.title(title.title(), fontsize=15, fontweight='bold')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(Image.open(glob.glob(f\"../{v_type.title()}/Posters/*_{v_ids[0]}.jpg\")[0]))\n",
    "\n",
    "        #**************************************\n",
    "        # We display the recommendations\n",
    "        #**************************************    \n",
    "        n = len(v_titles[1])\n",
    "        f2 = plt.figure(figsize=(20,6*n//5))\n",
    "        if reco_type == \"item-item\":\n",
    "            f2.suptitle(f\"If you like this movie, you might also like:\", fontsize=20, fontweight='bold')\n",
    "        elif reco_type == \"user-item\":\n",
    "            f2.suptitle(f\"Here are {n} {v_type} recommendations for user '{v_titles[0]}'\", fontsize=20, fontweight='bold')\n",
    "        elif reco_type == \"user_profile\":\n",
    "            f2.suptitle(f\"Here is the Top {n} {v_type} of user '{v_titles[0]}'\", fontsize=20, fontweight='bold')\n",
    "        for i in range(n):\n",
    "            f2.add_subplot(n//5,5,i+1)\n",
    "            title = v_titles[1][i][0]\n",
    "            split_title = title.split(\" \")\n",
    "            len_title = len(title)\n",
    "            title = title if len_title <= 21 else \" \".join(split_title[:len(split_title)//2]) + \"\\n\" + \" \".join(split_title[len(split_title)//2:])\n",
    "            plt.title(title.title(),fontweight='bold')\n",
    "            plt.axis('off')\n",
    "            if reco_type == \"item-item\":\n",
    "                plt.text(0, 470, f\"Similarity:\\n{v_titles[1][i][1]}\")\n",
    "            elif reco_type == \"user-item\":\n",
    "                plt.text(0, 470, f\"Rating prediction:\\n{v_titles[1][i][1]}\")\n",
    "            elif reco_type == \"user_profile\":\n",
    "                plt.text(0, 470, f\"User rating:\\n{v_titles[1][i][1]}\")\n",
    "            plt.imshow(Image.open(glob.glob(f\"../{v_type.title()}/Posters/*_{v_ids[1][i]}.jpg\")[0]))\n",
    "\n",
    "        plt.show(block=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model CB N¬∞1:** Genres with rating ponderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve only the useful columns for the content-based recommender system\n",
    "cols_to_keep = [\"id\", \"title\", \"release_date\", \"user_rating\", \"genres\"]\n",
    "v_type = \"movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dummies = get_dummies_df(df_key=v_type, keep_cols=cols_to_keep, cols_to_dummies=[\"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = movies_dummies.iloc[:,len(cols_to_keep):]\n",
    "norm_features_matrix = normalize_matrix(features_matrix, dummies_df=movies_dummies, binary=True, multiply_by_ratings=False, scaler=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the cosine similarity between each movie\n",
    "sim_matrix = compute_similarity(norm_features_matrix, \"cosine\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_titles, m_ids = CB_recommender(title=input(\"Enter a movie title or keywords: \"), sim_matrix=sim_matrix, nb_recos=10, dummies_df=movies_dummies)\n",
    "display_recos(m_titles, m_ids, v_type=v_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity between movies is very high, so a lot of movies with the highest similarity are recommended to the user. But depending on the original order of the movies, the order of the recommendations may change and therefore may not be very relevant. This is because we only considered the genres as a comparison criterion. We need to use more features or add a ponderation if we want to have a more accurate recommendation. \n",
    "\n",
    "So far, I obtained better recommendation by multiplying the correlation matrix by the movies' ratings. After reflexion, it appeared more sensible to multiply the encoded feature matrix by the ratings before computing the si√πilarity. In that way, movies with the same genres will more likely be similar if they have a high rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model CB N¬∞2:** Model 1 + tag analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve only the useful columns for the content-based recommender system\n",
    "cols_to_keep_2 = [\"id\", \"title\", \"release_date\", \"user_rating\", \"genres\", \"summary\"]\n",
    "v_type = \"movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dummies_2 = get_dummies_df(df_key=v_type, keep_cols=cols_to_keep_2, cols_to_dummies=[\"genres\", \"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix_2 = movies_dummies_2.iloc[:,len(cols_to_keep_2)+1:]\n",
    "norm_features_matrix_2 = normalize_matrix(features_matrix_2, dummies_df=movies_dummies_2, binary=True, multiply_by_ratings=False, scaler=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the cosine similarity between each movie and multiply it by the user rating.\n",
    "sim_matrix_2 = compute_similarity(norm_features_matrix_2, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_titles, m_ids = CB_recommender(title=input(\"Enter a movie title or keywords: \"), sim_matrix=sim_matrix_2, nb_recos=10, dummies_df=movies_dummies_2)\n",
    "display_recos(m_titles, m_ids, v_type=v_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second model, we used the titles of the movies to help recommend movies that, at first sight, may seem to talk about the same subject. What we notice from this new model is that movies with that share parts of their title are more likely to be recommended to the user, even though they have a lower rating. Moreover, as we decided to remove all punctuation marks and symbols characters, movies like `\"X-Men\"` will become `\"X Men\"`, and as both words are considered as stop-words, they will never be used to suggests on purpose other movies from the `\"X-Men Saga\"`. Movies with titles like `\"Le Monde de Narnia : Chapitre 1 - Le lion, la sorci√®re blanche et l'armoire magique\"` won't be affected by this characters removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model CB N¬∞3:** Model 1 + actors + directors + nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve only the useful columns for the content-based recommender system\n",
    "cols_to_keep_3 = [\"id\", \"title\", \"release_date\", \"duration\", \"user_rating\", \"genres\", \"actors\", \"directors\", \"nationality\"]\n",
    "v_type = \"movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dummies_3 = get_dummies_df(df_key=v_type, keep_cols=cols_to_keep_3, cols_to_dummies=[\"genres\", \"actors\", \"directors\", \"nationality\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\"release_date\", \"duration\"]\n",
    "features_matrix_3 = movies_dummies_3[numerical_cols + movies_dummies_3.iloc[:,len(cols_to_keep_3):].columns.to_list()]\n",
    "norm_features_matrix_3_minmax = normalize_matrix(features_matrix_3, dummies_df=movies_dummies_3, numerical_cols=numerical_cols, \n",
    "                                    cols_to_scale=[\"release_date\", \"duration\"] , binary=False, multiply_by_ratings=True, scaler=\"min-max\")\n",
    "norm_features_matrix_3_l1 = normalize_matrix(features_matrix_3, dummies_df=movies_dummies_3, numerical_cols=numerical_cols, \n",
    "                                    cols_to_scale=[\"release_date\", \"duration\"] , binary=False, multiply_by_ratings=True, scaler=\"l1\")\n",
    "norm_features_matrix_3_l2 = normalize_matrix(features_matrix_3, dummies_df=movies_dummies_3, numerical_cols=numerical_cols, \n",
    "                                    cols_to_scale=[\"release_date\", \"duration\"] , binary=False, multiply_by_ratings=True, scaler=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the cosine similarity between each movie and multiply it by the user rating.\n",
    "sim_matrix_3_minmax = compute_similarity(norm_features_matrix_3_minmax, similarity_metric=\"cosine\")\n",
    "sim_matrix_3_l1 = compute_similarity(norm_features_matrix_3_l1, similarity_metric=\"cosine\")\n",
    "sim_matrix_3_l2 = compute_similarity(norm_features_matrix_3_l2, similarity_metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CB N¬∞3 MIN-MAX\n",
    "m_titles, m_ids = CB_recommender(title=input(\"Enter a movie title or keywords: \"), sim_matrix=sim_matrix_3_minmax, nb_recos=10, dummies_df=movies_dummies_3)\n",
    "display_recos(m_titles, m_ids, v_type=v_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CB N¬∞3 L1\n",
    "m_titles, m_ids = CB_recommender(title=input(\"Enter a movie title or keywords: \"), sim_matrix=sim_matrix_3_l1, nb_recos=10, dummies_df=movies_dummies_3)\n",
    "display_recos(m_titles, m_ids, v_type=v_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CB N¬∞3 L2\n",
    "m_titles, m_ids = CB_recommender(title=input(\"Enter a movie title or keywords: \"), sim_matrix=sim_matrix_3_l2, nb_recos=10, dummies_df=movies_dummies_3)\n",
    "display_recos(m_titles, m_ids, v_type=v_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model CB N¬∞4:** Recommend movies from user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve only the useful columns for the content-based recommender system\n",
    "cols_to_keep_4 = [\"id\", \"title\", \"release_date\", \"duration\", \"user_rating\", \"genres\", \"actors\", \"directors\", \"nationality\"]\n",
    "v_type = \"movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dummies_4 = get_dummies_df(df_key=v_type, keep_cols=cols_to_keep_4, cols_to_dummies=[\"genres\", \"actors\", \"directors\", \"nationality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = []\n",
    "# We retrieve the features matrix of the movies\n",
    "features_matrix_4 = movies_dummies_4[numerical_cols + movies_dummies_4.iloc[:,len(cols_to_keep_4):].columns.to_list()]\n",
    "# We normalize the features matrix\n",
    "norm_features_matrix_4 = normalize_matrix(features_matrix_4, dummies_df=movies_dummies_4, numerical_cols=numerical_cols, \n",
    "                                    cols_to_scale=[] , binary=False, multiply_by_ratings=True, scaler=\"l2\")\n",
    "norm_features_matrix_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_titles, m_ids = CB_user_recommendations(user_movies_df=user_movies, dummies_df=movies_dummies_4, feature_matrix=features_matrix_4, norm_feature_matrix=norm_features_matrix_4, \n",
    "                                          drop_movies=False, top_movies=15, nb_recos=10)\n",
    "display_recos(m_titles, m_ids, v_type=v_type, reco_type=\"user-item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collaborative-Filtering (CF)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict user ratings: `predict_ratings(ratings, similarity, type)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(ratings: pd.DataFrame, similarity: np.array, type='user'):\n",
    "    '''\n",
    "    Predict ratings of user u for items k not yet rated.\n",
    "    :param ratings: utility matrix of ratings for users and items.\n",
    "    :param similarity: similarity matrix of users or items.\n",
    "    :param type: 'user' or 'item'.\n",
    "    :return: predicted ratings for items not yet rated, based on either user-user or item-item similarity.\n",
    "    '''\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1).values.reshape(-1, 1)\n",
    "        ratings_diff = (ratings - mean_user_rating)\n",
    "        pred = mean_user_rating + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CF Memory-Based recommendations: `CF_memory_based_recommendations(predictions, norm_utility_matrix, user_ids, movies, nb_recos)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF_memory_based_recommendations(prediction, norm_utility_matrix: pd.DataFrame, user_movies_df: pd.DataFrame=None, movies: pd.DataFrame=movies, drop_movies: bool=True, top_movies: int=5, nb_recos=10):\n",
    "    '''\n",
    "    Recommend movies for a user based on his/her ratings and on what other users have rated.\n",
    "    :param prediction: predicted ratings for items not yet rated.\n",
    "    :param norm_utility_matrix: normalized utility matrix of ratings for users and items.\n",
    "    :param user_movies_df: DataFrame of user ratings.\n",
    "    :param movies: DataFrame of movies.\n",
    "    :param drop_movies: boolean. If True, movies already rated by the user are dropped from the recommendations.\n",
    "    :param top_movies: Top top_movies favourite movies from the user's profile.\n",
    "    :param nb_recos: number of recommendations to return.\n",
    "    :return: Tuples of the recommended movies' titles, with similarity value and IDs.\n",
    "    '''\n",
    "    MB_recos = [] # Initialisation of the list of recommendations\n",
    "    movies_ids_list = [] # Initialization of the list of movie IDs \n",
    "\n",
    "    # Get all unique user ids sorted by the descending number of reviews\n",
    "    user_ids = user_movies_df.user_id.value_counts().index\n",
    "    \n",
    "    # Ask the user to choose a user\n",
    "    index = -1\n",
    "    while index < 0 or index >= len(user_ids):\n",
    "        index = int(input(f\"Enter the number of the user you want to get recommendations for (between 1 and {len(user_ids)}): \")) - 1\n",
    "    user_id = user_ids[index]\n",
    "    # Get all movies ID from user ID and their ratings\n",
    "    user_movie_list = user_movies[user_movies.user_id == user_id][[\"user_name\",\"movie_id\",\"user_rating\"]]\n",
    "    user_name = user_movie_list.user_name.values[0]\n",
    "    # Get all movies rated by the user\n",
    "    user_profile = movies.loc[movies[\"id\"].isin(user_movie_list.movie_id.to_list())]    \n",
    "    user_profile = user_profile.assign(user_rating=user_movie_list.user_rating.to_list())    \n",
    "\n",
    "    # Similarity matrix\n",
    "    index_users = norm_utility_matrix.index.values\n",
    "    index_movie_id = norm_utility_matrix.columns.values\n",
    "    user_similarity_df = pd.DataFrame(data=prediction, index=index_users, columns=index_movie_id)    \n",
    "    # We sort the similarity matrix and drop (or not) the movies already rated by the user\n",
    "    score_series = pd.Series(user_similarity_df.loc[user_id]).drop(user_movie_list.movie_id).sort_values(ascending=False) if drop_movies else pd.Series(user_similarity_df.loc[user_id]).sort_values(ascending=False)\n",
    "    top_nbrecos = list(score_series.iloc[0:nb_recos].index) # We select the most similar nb_recos movies to the movies the user has already seen\n",
    "    # We retrieve the titles of the top nb_recos movies in the list MB_recos and return it\n",
    "    for i in top_nbrecos:\n",
    "        MB_recos.append((movies[movies.id == i].title.iloc[0], user_similarity_df.at[user_id, i]))\n",
    "        movies_ids_list.append(i)\n",
    "        \n",
    "    #*********************************************\n",
    "    # Display the favourite movies of the user\n",
    "    #*********************************************\n",
    "    user_profile.sort_values(by=\"user_rating\", ascending=False, inplace=True)\n",
    "    user_movies_titles = [(user_profile.title.values[j], user_profile.user_rating.values[j]) for j in range(top_movies)]\n",
    "    display_recos((user_name, user_movies_titles), \n",
    "                  (None, user_profile.id.values[:top_movies]), \n",
    "                  v_type=\"movies\", reco_type=\"user_profile\")\n",
    "                  \n",
    "    return (user_name, MB_recos), (None, movies_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model CF N¬∞1:** *Memory-Based CF*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Item-based`: \n",
    "    - *¬´ Users who liked this item also liked... ¬ª*\n",
    "    - Selection of an item, find all users who interacted with this item, recommend the other items which the users have also interacted with.\n",
    "- `User-based`:\n",
    "    - *¬´ Users similar to you also liked... ¬ª*\n",
    "    - Selection of a user, find all user that have the same behaviour, recommend the items the other users also liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the user_movies df, remove users who appears less than 5 times (=> have made less than 5 reviews)\n",
    "user_movies_df = user_movies.groupby('user_id').filter(lambda x: len(x) >= 5)\n",
    "# Pivot table to get the user-movie utility matrix and fill missing values with 0\n",
    "utility_matrix = user_movies_df.pivot(index='user_id', columns='movie_id', values='user_rating').fillna(0)\n",
    "# We standardize the ratings \n",
    "norm_utility_matrix = normalize_matrix(utility_matrix, scaler=\"l2\")\n",
    "\n",
    "# We compute the similarity: Similarity = 1-distance\n",
    "user_similarity = 1-pairwise_distances(norm_utility_matrix, metric='cosine')\n",
    "item_similarity = 1-pairwise_distances(norm_utility_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings for items not yet rated, based on user-user or item-item similarity\n",
    "user_prediction = predict_ratings(norm_utility_matrix, user_similarity, type='user')\n",
    "item_prediction = predict_ratings(norm_utility_matrix, item_similarity, type='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL N¬∞1: CF_memory_based_recommendations (USER-BASED)\n",
    "m_titles, m_ids = CF_memory_based_recommendations(user_prediction, norm_utility_matrix, user_movies_df=user_movies_df, \n",
    "                                                  drop_movies=False, top_movies=15, nb_recos=15)\n",
    "display_recos(m_titles, m_ids, v_type=\"movies\", reco_type=\"user-item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL N¬∞2: CF_memory_based_recommendations (ITEM-BASED)\n",
    "m_titles, m_ids = CF_memory_based_recommendations(item_prediction, norm_utility_matrix, user_movies_df=user_movies_df, \n",
    "                                                  drop_movies=False, top_movies=15, nb_recos=15)\n",
    "display_recos(m_titles, m_ids, v_type=\"movies\", reco_type=\"user-item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY CF M1\n",
    "# DISPLAY FAVORITE MOVIES OF USERS\n",
    "# CF M2\n",
    "# MASTER METRICS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48c0ee024c6cc2421e377eb4076cadf4ce6eb7a4584917e3645e162e32894617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
