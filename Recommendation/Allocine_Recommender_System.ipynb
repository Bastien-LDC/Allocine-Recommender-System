{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¶**AlloCin√© Recommender System**üîéüìç\n",
    "\n",
    "Once we cleaned the data, we can start to build our recommender system. The data that will be used is located in the `../Cleaned Data/` folder.\n",
    "\n",
    "**Types of Recommender System:**\n",
    "\n",
    "There are two types of recommender system: **`content-based`** and **`collaborative-filtering`**.\n",
    "\n",
    "- **`Content-based`:** this recommender system is based only on the characteristics of the products. Here, we will recommend an item to a user by comparing the features between items and recommend the items with the highest similarity.\n",
    "\n",
    "- **`Collaborative-filtering`:** this recommender system is based on the interactions between users and the items. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Import libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ast import literal_eval\n",
    "from warnings import filterwarnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop # Used to get the French stop-words\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# We ignore dateparse warnings\n",
    "filterwarnings(\"ignore\",message=\"The localize method is no longer necessary, as this time zone supports the fold attribute\")\n",
    "# We ignore reindexing warnings\n",
    "filterwarnings(\"ignore\",message=\"Boolean Series key will be reindexed\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load the csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv():\n",
    "    '''\n",
    "    Load the csv files and return a dict of dataframes.\n",
    "    '''\n",
    "    root_path = f\"../Cleaned Data/\"\n",
    "    movies = pd.read_csv(f\"{root_path}movies.csv\", converters={\"genres\": literal_eval}) # Load list look-alike string as type list\n",
    "    series = pd.read_csv(f\"{root_path}series.csv\", converters={\"genres\": literal_eval})\n",
    "    press_movies = pd.read_csv(f\"{root_path}press_movies.csv\")\n",
    "    press_series = pd.read_csv(f\"{root_path}press_series.csv\")\n",
    "    user_movies = pd.read_csv(f\"{root_path}user_movies.csv\")\n",
    "    user_series = pd.read_csv(f\"{root_path}user_series.csv\")\n",
    "    #user_series = pd.read_csv(f\"../Series/Ratings/Webscraping_Series_Ratings_user_ratings_series_#1-1.csv\")\n",
    "    return {\"movies\":movies, \"series\":series, \"press_movies\":press_movies, \"press_series\":press_series, \"user_movies\":user_movies, \"user_series\":user_series}\n",
    "data = load_csv()\n",
    "movies, series, press_movies, press_series, user_movies, user_series = data[\"movies\"], data[\"series\"], data[\"press_movies\"], data[\"press_series\"], data[\"user_movies\"], data[\"user_series\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Content-based**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    '''\n",
    "    Get the French stop-words for tagging.\n",
    "    :return: list of French stop-words.\n",
    "    '''\n",
    "    # turn French stop-words into a list\n",
    "    stop_words = list(fr_stop)\n",
    "    # Load extra stop-words in French and in English\n",
    "    with open(\"stop_words_french.txt\",'r', encoding='UTF-8') as file:\n",
    "        additional_stopwords = file.readlines()\n",
    "        additional_stopwords = [line.rstrip() for line in additional_stopwords]\n",
    "    with open(\"stop_words_eng.txt\",'r', encoding='UTF-8') as file:\n",
    "        additional_stopwords_eng = file.readlines()\n",
    "        additional_stopwords_eng = [line.rstrip() for line in additional_stopwords_eng]\n",
    "    \n",
    "    # Add the additional French stop-words to the list of stop-words if they are not already in it\n",
    "    for word, word_eng in zip(additional_stopwords,additional_stopwords_eng):\n",
    "        if word not in stop_words:\n",
    "            stop_words.append(word)\n",
    "        if word_eng not in stop_words:\n",
    "            stop_words.append(word_eng)\n",
    "    stop_words.extend([\"\",\" \",\"#\",\"-\",\":\",\"(\",\")\"])\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(df: pd.DataFrame=None, stop_words: list=get_stop_words(), cols_to_get: str=\"title\"):\n",
    "    '''\n",
    "    Get the tags of the movies from the title and/or summary.\n",
    "    :param df: Dataframe to transform.\n",
    "    :param stop_words: List of stop-words to remove from the tags.\n",
    "    :param col_to_get: Columns to get the tags from.\n",
    "    '''\n",
    "    try:\n",
    "        # We remove unecessary punctuation and characters from the title \n",
    "        # And store the title's keywords in a list\n",
    "        rmv_char = r\"(!|#|:|\\$|\\%|\\^|\\&|\\*|\\(|\\)|-|\\+|/|\\?|\\.+|\\d)\"\n",
    "        df[\"tags\"] = df[cols_to_get].apply(lambda x: re.split(\" |,|\\. |\\.\\.\\.|\\\"|'|-\", re.sub(rmv_char, \" \", x)))\n",
    "        df[\"tags\"] = df[\"tags\"].apply(lambda x: [i for i in x if i.lower() not in stop_words])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies_df(df: pd.DataFrame=None, keep_cols: list=None, col_to_dummies: list=None):\n",
    "    '''\n",
    "    Get a dataframe with the dummies of the column col_to_dummies.\n",
    "    :param df: Dataframe to transform.\n",
    "    :param keep_cols: List of columns to keep.\n",
    "    :param col_to_dummies: List of columns to transform to dummies.\n",
    "    '''\n",
    "    try:\n",
    "        df_dummies = df[keep_cols]\n",
    "        # We drop the movies with no user rating\n",
    "        df_dummies = df_dummies.dropna(subset=[\"user_rating\"], axis=0)\n",
    "        df_dummies = df_dummies.reset_index(drop=True)\n",
    "        \n",
    "        # We add the tag column to the dataframe\n",
    "        if \"tags\" in col_to_dummies:\n",
    "            df_dummies = get_tags(df=df_dummies) \n",
    "\n",
    "        non_dummy_cols = df_dummies.shape[1]\n",
    "\n",
    "        # We create binary variables for each genre by One-Hot encoding the genres column    \n",
    "        encoded_genres = pd.get_dummies(df_dummies.genres.apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "        df_dummies = pd.concat([df_dummies, encoded_genres], axis=1).sort_values(by=[\"title\", \"release_date\"], ascending=[True,False])\n",
    "        df_dummies.reset_index(drop=True, inplace=True)       \n",
    "            \n",
    "        if \"tags\" in col_to_dummies:\n",
    "            encoded_tags = pd.get_dummies(df_dummies.tags.apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "            df_dummies = pd.concat([df_dummies, encoded_tags], axis=1)\n",
    "                \n",
    "        # We replace NaN values in the dummy columns with 0\n",
    "        df_dummies.iloc[:,non_dummy_cols:] = df_dummies.iloc[:,non_dummy_cols:].fillna(0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    return df_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model N¬∞1:** Genres with rating ponderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve only the useful columns for the content-based recommender system\n",
    "cols_to_keep = [\"id\", \"title\", \"release_date\", \"user_rating\", \"genres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dummies = get_dummies_df(df=movies, keep_cols=cols_to_keep, col_to_dummies=[\"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the cosine similarity between each movie and multiply it by the user rating.\n",
    "cos_sim = cosine_similarity(movies_dummies.iloc[:,-(movies_dummies.shape[1]-len(cols_to_keep)):]) * movies_dummies.user_rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_recommender(title: str=\"The Batman\", cos_sim=cos_sim, nb_recos: int=10, dummies_df: pd.DataFrame=movies_dummies):\n",
    "    '''\n",
    "    Get the recommendations for a movie.\n",
    "    :param title: Title of the movie to get the recommendations for.\n",
    "    :param cos_sim: Cosine similarity matrix.\n",
    "    :param nb_recos: Number of recommendations to get.\n",
    "    :param dummies_df: Dataframe with the dummies of the movies.\n",
    "    :return: List of nb_recos recommendations.    \n",
    "    '''\n",
    "    CB_recos = [] # Initialisation of the list of recommendations\n",
    "    title_keywords = title.split(\" \") # We split the title into keywords\n",
    "    title_list = []\n",
    "    # We collect all the movies titles which contain all the keywords of the title\n",
    "    for full_title in dummies_df.title.values.tolist():\n",
    "        if all(word.lower() in full_title.lower() for word in title_keywords):\n",
    "            title_list.append(full_title)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    # If we get a direct match, we return the title.    \n",
    "    if len(title_list) == 1:\n",
    "        current_title = title_list[0]\n",
    "    # Else, we get all the movies with similar names and ask the user to choose one.\n",
    "    elif len(title_list) > 1:\n",
    "        print(\"Several movies found with similar title. Please choose one of the following:\")\n",
    "        for i, item in enumerate(title_list,1):\n",
    "            print(i, ': ' + item, sep='',end='\\n')\n",
    "        choice = -1\n",
    "        while choice < 1 or choice > len(title_list):\n",
    "            choice = int(input(\"Enter the number of the movie: \"))\n",
    "        current_title = title_list[choice-1]\n",
    "    else:\n",
    "        return f'Error: The movie {title} requested was not found.'\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f\"The movie you requested is: \\\"{current_title}\\\"\\nIf you like this movie, you might also like:\")\n",
    "    # If the movie is in the database\n",
    "    idx = dummies_df.index[dummies_df.title == current_title][0] # We retrieve the index of the movie (the most recent one if there are homonyms)\n",
    "    score_series = pd.Series(cos_sim[idx]).drop(idx).sort_values(ascending=False) # We sort the similarity matrix of the movies and we drop the movie itself\n",
    "    top_nbrecos = list(score_series.iloc[0:nb_recos].index) # We select the top nb_recos movies \n",
    "    # We store the titles of the top nb_recos movies in the list CB_recos and return it\n",
    "    for i in top_nbrecos:             \n",
    "        CB_recos.append((dummies_df.title[i], cos_sim[idx][i]))\n",
    "    return CB_recos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you requested is: \"Avengers\"\n",
      "If you like this movie, you might also like:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Star Wars : Episode III - La Revanche des Sith', 4.200000000000001),\n",
       " ('Rogue One: A Star Wars Story', 4.1000000000000005),\n",
       " ('La Plan√®te des singes : les origines', 4.1000000000000005),\n",
       " ('Star Trek Into Darkness', 4.000000000000001),\n",
       " ('Star Trek', 3.900000000000001),\n",
       " (\"Captain America, le soldat de l'hiver\", 3.900000000000001),\n",
       " ('La Plan√®te des Singes - Supr√©matie', 3.900000000000001),\n",
       " ('Plan√®te interdite', 3.8000000000000007),\n",
       " (\"Avengers : L'√®re d'Ultron\", 3.8000000000000007),\n",
       " ('Stargate, la porte des √©toiles', 3.700000000000001)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CB_recommender(title=input(\"Enter a movie title or keywords: \"), cos_sim=cos_sim, nb_recos=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity between movies is very high, so a lot of movies with the highest similarity are recommended to the user. But depending on the original order of the movies, the order of the recommendations may change and therefore may not be very relevant. This is because we only considered the genres as a comparison criterion. We need to use more features or add a ponderation if we want to have a more accurate recommendation. \n",
    "\n",
    "So far, I obtained better recommendation by multiplying the correlation matrix by the movies' ratings. In that way, movies with the same genres will more likely be similar if they have a high rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model N¬∞2:** Model 1 + tag analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve only the useful columns for the content-based recommender system\n",
    "cols_to_keep_2 = [\"title\", \"release_date\", \"user_rating\", \"genres\", \"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dummies_2 = get_dummies_df(df=movies, keep_cols=cols_to_keep_2, col_to_dummies=[\"genres\", \"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the cosine similarity between each movie and multiply it by the user rating.\n",
    "cos_sim_2 = cosine_similarity(movies_dummies_2.iloc[:,-(movies_dummies_2.shape[1]-len(cols_to_keep_2) - 1):]) * movies_dummies_2.user_rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you requested is: \"Pirates des Cara√Øbes : la Mal√©diction du Black Pearl\"\n",
      "If you like this movie, you might also like:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"Pirates des Cara√Øbes : Jusqu'au Bout du Monde\", 2.114285714285714),\n",
       " ('Pirates des Cara√Øbes : le Secret du Coffre Maudit', 2.08463768691691),\n",
       " ('Pirates des Cara√Øbes : la Vengeance de Salazar', 1.9999999999999996),\n",
       " ('Black Panther', 1.7590581895678477),\n",
       " ('Spider-Man', 1.7457431218879391),\n",
       " ('Predator', 1.658455965793542),\n",
       " ('Spider-Man 2', 1.658455965793542),\n",
       " ('Black', 1.5275252316519468),\n",
       " ('Aquaman', 1.5275252316519468),\n",
       " ('Spider-Man 3', 1.5275252316519468)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CB_recommender(title=input(\"Enter a movie title or keywords: \"), cos_sim=cos_sim_2, nb_recos=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second model, we used the titles of the movies to help recommend movies that, at first sight, may seem to talk about the same subject. What we notice from this new model is that movies with that share parts of their title are more likely to be recommended to the user, even though they have a lower rating. Moreover, as we decided to remove all punctuation marks and symbols characters, movies like `\"X-Men\"` will become `\"X Men\"`, and as both words are considered as stop-words, they will never be used to suggests on purpose other movies from the `\"X-Men Saga\"`. Movies with titles like `\"Le Monde de Narnia : Chapitre 1 - Le lion, la sorci√®re blanche et l'armoire magique\"` won't be affected by this characters removal."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48c0ee024c6cc2421e377eb4076cadf4ce6eb7a4584917e3645e162e32894617"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
